---
  hpc: False
  local_root: /home/mv23682/Documents/Abil/
  hpc_root: /user/work/mv23682/Abil/

  path_out: ModelOutput/ #root + folder
  path_in: ModelOutput/mapie/predictions/ #root + folder

  env_data_path: wiseman2024/data/env_data_no_sat.csv #root + folder
  targets: wiseman2024/data/traits_calc.csv #root + folder
  training: wiseman2024/data/calcif_env.csv

  predictors: ["temperature", 
    "si", "phosphate", "din", 
    "o2", "mld", "DIC", "TA"]
 
    
  verbose: 1
  seed : 1 # random seed
  n_threads : 10 # how many cpu threads to use
  cv : 10
  predict_probability: False 

  ensemble_config: 
    classifier: False
    regressor: True
    m1: "rf"
    m2: "xgb"
    m3: "knn"
    #m4: "mlp"
     
  upsample: False
  stratify: False

  reg_scoring:
   R2: r2
   MAE: neg_mean_absolute_error
   RMSE: neg_root_mean_squared_error
   tau: kendall_tau

  param_grid:
    rf_param_grid:
      reg_param_grid:
        regressor__estimator__n_estimators: [250]
        regressor__estimator__max_features:  ['sqrt', 0.1, 0.2, 0.4, 0.6, 0.8, 1]
        regressor__estimator__max_depth: [2, 10, 51, 75, 100]
        regressor__estimator__min_samples_leaf: [1, 5, 13, 25, 37, 50]
        regressor__estimator__max_samples: [0.6, 0.7, 0.75, 0.8, 0.85, 0.9, 1]   

    xgb_param_grid:
      reg_param_grid:  
        regressor__estimator__learning_rate: [0.01, 0.015, 0.025, 0.05, 0.1]
        regressor__estimator__n_estimators: [100]
        regressor__estimator__max_depth: [2, 5, 7, 10, 51, 100]
        regressor__estimator__subsample: [0.4, 0.6, 0.7, 0.8, 1]
        regressor__estimator__colsample_bytree: [0.5, 0.667, 0.8, 0.9, 0.95, 0.975, 1]
        regressor__estimator__gamma: [0] 
        regressor__estimator__reg_alpha: [0, 0.1]

    knn_param_grid:
      reg_param_grid:  
        regressor__estimator__max_samples: [0.6, 0.8, 0.85, 0.9, 1]
        regressor__estimator__max_features: [0.6, 0.8, 0.85, 0.9, 1]
        regressor__estimator__estimator__leaf_size: [10, 30, 50]
        regressor__estimator__estimator__n_neighbors: [1, 3, 5, 8]
        regressor__estimator__estimator__p:  [1,2]        
        regressor__estimator__estimator__weights: ["uniform", "distance"]

    mlp_param_grid:
      reg_param_grid:
        regressor__estimator__hidden_layer_sizes: [[20,10,],[10,10,],[15,15,],[10,20,]]
        regressor__estimator__learning_rate_init: [0.01, 0.05, 0.1]
        regressor__estimator__alpha: [0.0001,0.0005,0.001,0.005] # typically the main tuning parameter
  knn_bagging_estimators: 30

